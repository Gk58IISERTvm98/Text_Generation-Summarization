{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding, LSTM, Dropout, Dense\n\n# Tokenizer initialization\ntokenizer = Tokenizer()\n","metadata":{"execution":{"iopub.status.busy":"2024-09-02T19:10:40.160852Z","iopub.execute_input":"2024-09-02T19:10:40.161315Z","iopub.status.idle":"2024-09-02T19:10:44.989265Z","shell.execute_reply.started":"2024-09-02T19:10:40.161252Z","shell.execute_reply":"2024-09-02T19:10:44.988269Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import keras\n\npath = keras.utils.get_file(\n    'nietzsche.txt',\n    origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\ntext = open(path).read().lower()\nprint('Corpus length:', len(text))","metadata":{"execution":{"iopub.status.busy":"2024-09-02T19:11:45.993245Z","iopub.execute_input":"2024-09-02T19:11:45.994636Z","iopub.status.idle":"2024-09-02T19:11:46.012506Z","shell.execute_reply.started":"2024-09-02T19:11:45.994581Z","shell.execute_reply":"2024-09-02T19:11:46.011231Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Corpus length: 600893\n","output_type":"stream"}]},{"cell_type":"code","source":"def dataset_preparation(data):\n    data = data.lower().split(\"\\n\")\n    tokenizer.fit_on_texts(data)\n    total_words = len(tokenizer.word_index) + 1\n\n    # create input sequences using list of tokens\n    input_sequences = []\n    for line in data:\n        token_list = tokenizer.texts_to_sequences([line])[0]\n        for i in range(1, len(token_list)):\n            n_gram_sequence = token_list[:i+1]\n            input_sequences.append(n_gram_sequence)\n\n    # pad sequences\n    max_sequence_len = max([len(x) for x in input_sequences])\n    input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n\n    # create predictors and label\n    predictors, label = input_sequences[:, :-1], input_sequences[:, -1]\n    label = to_categorical(label, num_classes=total_words)\n\n    return predictors, label, max_sequence_len, total_words","metadata":{"execution":{"iopub.status.busy":"2024-09-02T19:11:49.597909Z","iopub.execute_input":"2024-09-02T19:11:49.598382Z","iopub.status.idle":"2024-09-02T19:11:49.607968Z","shell.execute_reply.started":"2024-09-02T19:11:49.598338Z","shell.execute_reply":"2024-09-02T19:11:49.606736Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"predictors, label, max_sequence_len, total_words = dataset_preparation(text)","metadata":{"execution":{"iopub.status.busy":"2024-09-02T19:12:05.141893Z","iopub.execute_input":"2024-09-02T19:12:05.142391Z","iopub.status.idle":"2024-09-02T19:12:06.819420Z","shell.execute_reply.started":"2024-09-02T19:12:05.142343Z","shell.execute_reply":"2024-09-02T19:12:06.817543Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def create_model(predictors, label, max_sequence_len, total_words):\n    input_len = max_sequence_len - 1\n    model = Sequential()\n    model.add(Embedding(total_words, 10, input_length=input_len))\n    model.add(LSTM(150))\n    model.add(Dropout(0.1))\n    model.add(Dense(total_words, activation='softmax'))\n    model.compile(loss='categorical_crossentropy', optimizer='adam')\n    model.fit(predictors, label, epochs=10, verbose=1)\n    print(model.summary())\n    return model","metadata":{"execution":{"iopub.status.busy":"2024-09-02T19:12:18.033324Z","iopub.execute_input":"2024-09-02T19:12:18.034178Z","iopub.status.idle":"2024-09-02T19:12:18.041586Z","shell.execute_reply.started":"2024-09-02T19:12:18.034129Z","shell.execute_reply":"2024-09-02T19:12:18.040362Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"model = create_model(predictors, label, max_sequence_len, total_words)","metadata":{"execution":{"iopub.status.busy":"2024-09-02T19:12:26.470567Z","iopub.execute_input":"2024-09-02T19:12:26.471028Z","iopub.status.idle":"2024-09-02T19:31:29.598404Z","shell.execute_reply.started":"2024-09-02T19:12:26.470985Z","shell.execute_reply":"2024-09-02T19:31:29.596770Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/10\n\u001b[1m2886/2886\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 31ms/step - loss: 6.8532\nEpoch 2/10\n\u001b[1m2886/2886\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 31ms/step - loss: 6.2841\nEpoch 3/10\n\u001b[1m2886/2886\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 31ms/step - loss: 6.0612\nEpoch 4/10\n\u001b[1m2886/2886\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 31ms/step - loss: 5.8661\nEpoch 5/10\n\u001b[1m2886/2886\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 31ms/step - loss: 5.6481\nEpoch 6/10\n\u001b[1m2886/2886\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 36ms/step - loss: 5.4297\nEpoch 7/10\n\u001b[1m2886/2886\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 31ms/step - loss: 5.2601\nEpoch 8/10\n\u001b[1m2886/2886\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 30ms/step - loss: 5.0496\nEpoch 9/10\n\u001b[1m2886/2886\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 30ms/step - loss: 4.8494\nEpoch 10/10\n\u001b[1m2886/2886\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 31ms/step - loss: 4.6714\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m10\u001b[0m)         │       \u001b[38;5;34m102,620\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m)            │        \u001b[38;5;34m96,600\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10262\u001b[0m)          │     \u001b[38;5;34m1,549,562\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">102,620</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">96,600</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10262</span>)          │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,549,562</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,246,348\u001b[0m (20.01 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,246,348</span> (20.01 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,748,782\u001b[0m (6.67 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,748,782</span> (6.67 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m3,497,566\u001b[0m (13.34 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,497,566</span> (13.34 MB)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"None\n","output_type":"stream"}]},{"cell_type":"code","source":"def apply_temperature(preds, temperature=1.0):\n    if temperature == 0:\n        temperature = 1e-7  # Avoid division by zero\n    preds = np.log(preds + 1e-9) / temperature\n    exp_preds = np.exp(preds)\n    preds = exp_preds / np.sum(exp_preds)\n    return preds","metadata":{"execution":{"iopub.status.busy":"2024-09-02T19:31:29.600572Z","iopub.execute_input":"2024-09-02T19:31:29.600963Z","iopub.status.idle":"2024-09-02T19:31:29.607703Z","shell.execute_reply.started":"2024-09-02T19:31:29.600923Z","shell.execute_reply":"2024-09-02T19:31:29.606512Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def generate_text(seed_text, next_words, max_sequence_len, model, temperature=1.0):\n    for _ in range(next_words):\n        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n        preds = model.predict(token_list, verbose=0)[0]\n\n        # Apply temperature scaling\n        scaled_preds = apply_temperature(preds, temperature)\n\n        # Sample the next word from the scaled probability distribution\n        next_word_index = np.random.choice(len(scaled_preds), p=scaled_preds)\n        \n        # Find the word corresponding to the predicted index\n        output_word = \"\"\n        for word, index in tokenizer.word_index.items():\n            if index == next_word_index:\n                output_word = word\n                break\n\n        seed_text += \" \" + output_word\n    return seed_text","metadata":{"execution":{"iopub.status.busy":"2024-09-02T19:31:29.609302Z","iopub.execute_input":"2024-09-02T19:31:29.609668Z","iopub.status.idle":"2024-09-02T19:31:29.627258Z","shell.execute_reply.started":"2024-09-02T19:31:29.609632Z","shell.execute_reply":"2024-09-02T19:31:29.626041Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Example usage with correct argument types\nseed_text = \"new faculty, and the jubilation reached its climax when kant.\"\nnext_words = 50  # The number of words to generate (must be an integer)\ntemperature = 0.8\n\ngenerated_text = generate_text(seed_text, next_words=next_words, max_sequence_len=max_sequence_len, model=model, temperature=temperature)\nprint(generated_text)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-02T19:35:55.895212Z","iopub.execute_input":"2024-09-02T19:35:55.896345Z","iopub.status.idle":"2024-09-02T19:35:59.667696Z","shell.execute_reply.started":"2024-09-02T19:35:55.896296Z","shell.execute_reply":"2024-09-02T19:35:59.666407Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"new faculty, and the jubilation reached its climax when kant. is always still so a imaginations of humanity as he could does seem to do a thinker of knowledge as a sudden than of life and extraordinarily we have too among means of the history of sympathy and the eternal word the faith be the takes his cruelty as germans\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}